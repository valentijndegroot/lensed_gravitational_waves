import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from matplotlib import rcParams
rcParams['text.usetex'] = True
rcParams['text.latex.preamble'] = [r'\usepackage{amsmath}']
rcParams['font.family'] = 'sans-serif'
import matplotlib.font_manager as font_manager
import matplotlib
%matplotlib qt
import pathlib
import cv2
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

###############################################

#We import the spectrograms which were generated by the data visualisation file.

CATEGORIES = ['Unlensed_Spec', 'Lensed_Spec']
for category in CATEGORIES:
    path = os.path.join(data_dir, category) 
    
img_height = 288
img_width = 432   

data = []
images = []
labels = []

def create_data():
    for i in range(len(CATEGORIES)):
        category = CATEGORIES[i]
        path = os.path.join(data_dir, category)
        for img in os.listdir(path):
            img_array = cv2.imread(os.path.join(path,img))
            img_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
            #new_array = cv2.resize(img_array, (img_width, img_height))
            data.append([img_rgb, i])
            images.append(img_rgb)
            labels.append(i)
    return data, images, labels
    
data, images, labels = create_data()

###############################################

#We make train, validate and test data

from sklearn.model_selection import train_test_split
X_train, X_testval, y_train, y_testval  = train_test_split(images, labels, test_size=0.2, random_state=1)
X_val, X_test, y_val, y_test  = train_test_split(X_testval, y_testval, test_size=0.5, random_state=1)
X_train = np.array(X_train)
X_test = np.array(X_test)
X_val = np.array(X_val)
y_train = np.array(y_train)
y_test = np.array(y_test)
y_val = np.array(y_val)

###############################################

#We build a simple CNN with SELU activation functions.

num_classes = 2
from tensorflow.keras import regularizers

model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='selu'), 
  layers.MaxPooling2D(), #2x2 kernel size
  layers.Conv2D(32, 3, padding='same', activation='selu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='selu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 3, padding='same', activation='selu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='selu', activity_regularizer=regularizers.L2(1e-5)),  #I eventually dropped the regularisation here
  layers.Dense(1, activation = 'sigmoid')
  #layers.Dense(num_classes, activation = 'softmax')
])

#We use the SparseCategoricalCrossentropy as loss function. If you would use one hot encoding, one would just take 
#CategoricalCrossentropy. sparse_categorical_crossentropy ( scce ) produces a category index of the most 
#likely matching category.

#If the model is solving a multi-class classification problem, logits typically become an input to the softmax function.
#The softmax function then generates a vector of (normalized) probabilities with one value for each possible class.

opt = keras.optimizers.Adam(learning_rate=0.00001)
model.compile(optimizer= opt,
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])
	     
###############################################

import keras
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint

epochs=150
batch_size = 32

callback = [EarlyStopping(monitor='val_loss', patience=10, verbose = 1),
             ModelCheckpoint(filepath='best_model_selu_regularisation.h5', monitor='val_loss', verbose=1,save_best_only=True)]

#We train the model 

history = model.fit(
  X_train,
  y_train,  
  validation_data=(X_val, y_val),
  epochs=epochs,
  batch_size = batch_size,
  verbose = True,
  callbacks = callback
)

###############################################

#model.save('selu')
#np.save('historyselu.npy',history.history)

#Once the model is saved, we can easily use it later by loading the model

reconstructed_model = keras.models.load_model('best_model_selu.h5')
#reconstructed_model = model

###############################################

#We use the loaded model to make predictions on the test set.
#predicted returns probabilities for every image for lensed and unlensed. 
#We create a new list with binaries whether it is listed or not. 
#0 is unlensed, 1 is lensed. If the prob is higher than threshold, we assign 1, else we assign 0.

predicted = reconstructed_model.predict(X_test)
predictedlabels = []
for i in range(0,len(predicted)):
    if predicted[i][0] > 0.36:
        predictedlabels.append(1)   #unlensed get value 0, lensed get value 1.
    else:
        predictedlabels.append(0) 
    
#We check the accuracy metrics
print(accuracy_score(y_test, predictedlabels))
print(recall_score(y_test, predictedlabels))
print(f1_score(y_test, predictedlabels))

###############################################

#We generate the ROC curve

from sklearn import datasets, metrics, model_selection, svm
from sklearn.metrics import roc_curve

fpr, tpr, treshold = roc_curve(y_test,predicted) 
fig = plt.figure(1)
ax = fig.add_subplot()
line, =plt.plot(fpr,tpr, label = r'$\mathrm{CNN - ELU (AUC = 0.99)}$',linewidth =4)
ax.legend(handles=[line],fontsize=60)
ax.set_ylabel(r'$\mathrm{True\, Positive\, Rate\,}\newline \mathrm{\,\, (Positive\, label:\, 1)}$',fontsize=60)
ax.set_xlabel(r'$\mathrm{False\, Positive\, Rate\, (Positive\, label:\, 1)}$',fontsize=60)
ax.yaxis.get_offset_text().set_fontsize(60)
ax.tick_params(axis='both',  labelsize=60)
ax.set_xticks(np.linspace(0, 1, 5))
ax.set_yticks(np.linspace(0, 1, 5))

###############################################

#We generate the confusion matrix

from sklearn.metrics import confusion_matrix
import seaborn as sns

#Generate the confusion matrix
cf_matrix = confusion_matrix(y_test, predictedlabels)

group_names = [r'$\mathrm{True\, Unlensed}$','$\mathrm{False\, Lensed}$','$\mathrm{False\, Unlensed}$','$\mathrm{True\, Lensed}$']

group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]

group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]

label = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

label = np.asarray(label).reshape(2,2)

ax = sns.heatmap(cf_matrix, annot=label, fmt='', cmap='Blues',annot_kws={"size": 60},cbar=False)

ax.set_xlabel('$\mathrm{Predicted\, Values}$',fontsize = 60)
ax.set_ylabel('$\mathrm{Actual\, Values }$', fontsize =60);

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['$\mathrm{Unlensed}$','$\mathrm{Lensed}$'])
ax.yaxis.set_ticklabels(['$\mathrm{Unlensed}$','$\mathrm{Lensed}$'],va="center")
ax.yaxis.get_offset_text().set_fontsize(60)
ax.tick_params(axis='both',  labelsize=60)

## Display the visualization of the Confusion Matrix.
#plt.savefig(r'...', dpi =300)
plt.show()

###############################################

#We visualise how the spectrograms look like after the learned convolutional layers

for i in range(len(reconstructed_model.layers)):
    layer = reconstructed_model.layers[i]
    # check for convolutional layer
    if 'conv' not in layer.name:
        continue
    # summarize output shape
    print(i, layer.name, layer.output.shape)
    
from keras.models import Model
print(reconstructed_model.layers[1])
ixs = [1,3,5,7]
outputs = [reconstructed_model.layers[i].output for i in ixs]
model2 = Model(inputs=reconstructed_model.inputs, outputs=outputs)
# redefine model to output right after the first hidden layer
#model = Model(inputs=model.inputs, outputs=model.layers[2].output)

# load the image with the required shape
imgnumber = 1005
img = images[imgnumber].astype("uint8").reshape(1,288,432,3)   #the 1 is that we now have a batch of size 1
#img = first_image
plt.figure(1)
plt.imshow(images[imgnumber].astype("uint8"))
# convert the image to an array
#img = img_to_array(img)
# expand dimensions so that it represents a single 'sample'
#img = expand_dims(img, axis=0)
# prepare the image (e.g. scale pixel values for the vgg)
#img = preprocess_input(img)
# get feature map for first hidden layer
feature_maps = model2.predict(img)
# plot all 16 maps in an 4x4 squares
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
#This displays how the figure looks like after every convolutional layer, so you begin the see on which the convolutional layer 
#focuses. After the first convolutional layer, we have 16 channels, after the last one 128. We display for every level 16 
#channels                           

plt.figure(2)
square = 4
for fmap in feature_maps:
	# plot 16 maps in an 4x4 squares,first layer has 16 maps, second 32 and third 64, we plot just first 16
	ix = 1
	for _ in range(square):
		for _ in range(square):
			# specify subplot and turn of axis
			ax = plt.subplot(square, square, ix)
			ax.set_xticks([])
			ax.set_yticks([])
			# plot filter channel in grayscale
			plt.imshow(fmap[0, :, :, ix-1], cmap='gray')
			ix += 1
	# show the figure
	plt.show()

